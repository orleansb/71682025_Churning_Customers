# -*- coding: utf-8 -*-
"""baaba_boham_assign3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ohdgSvWQlkUIQbEobZjQMcd4CloPk1gc
"""

from google.colab import drive
drive.mount('/content/drive')

pip install scikeras

"""# Importing relevant libraries

"""

import pandas as pd
import numpy as np
import sklearn
import numpy as np
import pandas as pd
import numpy as np, pandas as pd
from sklearn import tree, metrics
from keras.models import Sequential
from sklearn.preprocessing import  LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from keras.models import Model
from keras.layers import Input, Dense
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import cross_val_score
from tensorflow.keras.models import load_model
import joblib
import pickle

pip install pyyaml h5py

from scikeras.wrappers import KerasClassifier, KerasRegressor

"""# Reading the data into a dataframe

"""

customer_churn = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CustomerChurn_dataset.csv')

"""# Data Pre-processing"""

customer_churn.info()

churn = pd.DataFrame(customer_churn)

churn = churn.drop('customerID', axis = 1)

"""*Picking the target variable*"""

y = churn['Churn']
churn_answer = y

churn2 = churn
churn2

"""*Dropping the target variable*"""

churn = churn.drop('Churn', axis = 1)
churn1 = churn

"""*Seperating the attributes into numerical and categorical*"""

values = ['TotalCharges','tenure', 'MonthlyCharges']
numerical = churn[values]
churn = churn.drop(numerical , axis =1)
categorical =  churn.select_dtypes(include=['object'])

churn = churn.drop(categorical, axis = 1)

"""*Encoding the independent variables*"""

label_encoder = LabelEncoder()

label_encoded = categorical.apply(lambda x: label_encoder.fit_transform(x))
categorical_values = pd.DataFrame(label_encoded)

label_encode = label_encoder.fit_transform(y)
y = pd.DataFrame(label_encode)

"""*Saving the label encoder for deployment*"""

np.save('classes.npy', label_encoder.classes_)

"""*Concatinating the encoded categorical variables with the numerical values*"""

churn =  pd.concat([churn,categorical_values], axis=1)
churn = pd.concat([churn, numerical], axis =1)
churn

"""*replacing missing values wth NaN and filling the values*"""

churn['TotalCharges'] = churn['TotalCharges'].replace(' ', np.nan)
churn['TotalCharges']

churn['TotalCharges'] = churn['TotalCharges'].fillna(0).astype(float)

churn.info()

"""*Scaling the data*

# Feature Importance
"""

model = RandomForestClassifier(n_estimators=100, random_state=0)
model.fit(churn, y)

feature_importance = model.feature_importances_
feature_names = churn.columns

importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})
feature_importance = importance_df.sort_values(by='Importance', ascending=False)

feature_importance

"""**Selecting relevant features**"""

features = feature_importance['Feature'].values[:10]

features

churn = churn[features]
churn

"""*Scaling the relevant features*"""

scaler = StandardScaler()

scaled = scaler.fit_transform(churn)
churn = pd.DataFrame(scaled, columns=churn.columns)
churn

"""*Saving the scaler for deployment*"""

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

"""# Exploratory Data Analysis"""

categorical = ['Contract', 'PaymentMethod', 'TechSupport', 'OnlineSecurity', 'InternetService', 'gender', 'OnlineBackup']
numerical  = ['TotalCharges', 'MonthlyCharges', 'tenure']
numerical_values = churn[numerical]
categorical_values = churn1[categorical]

"""**Visualizing the numerical features**"""

import seaborn as sns
import matplotlib.pyplot as plt
for i in numerical_values:
  sns.histplot(numerical_values[i], bins=50, kde=True)
  plt.show()

"""**Visualizing the categorical features**

Total charges is skewed to the right which implies that major of the customers have low total charges with few having very high total charges

Monthly charges on the other hand is left skewed with a few outliers

Tenure is almost symmetrically distributed
"""

for i in categorical_values:
  sns.countplot(x= i, data=categorical_values)
  plt.show()

"""
1.  From the above graphs it can be seen that more customers opt for the
month-to-month contract than the one and two year contracts
2.  More customers prefer using electronic checks to pay their bills
3. Most customers do not have tech support, online backup and online security
4. Majority of the customers use fibre optic internet followed by dsl with few having no internet service at all
5. There is almost an equal number of males and females




"""

churn2

"""**Visualizing the categorical variables against the dependent variable churn**"""

for i in categorical_values:
  sns.countplot(x=i, hue= 'Churn', data=churn2)
  plt.title('Bar Plot of Dependent Variable by Independent Variable')
  plt.show()

"""People who are using the month to month contract churn more than those using the other contracts and those on the 2 year contract have a lower churn
People using the electronic checks to pay have a higher churn than those who do not
Both females and males have the same level of churning

creating a dataframe that contains churn and the numerical features in order to visualize them
"""

all_numeric =  pd.concat([numerical_values, churn_answer], axis=1)

all_numeric

"""Visualizing the relevant numerical variables against churn"""

for i in numerical_values:
    sns.boxplot(x='Churn', y = i, data = all_numeric)
    plt.title(f'Box Plot of {i} by Churn')
    plt.show()

for i in range(len(categorical_values.columns)-2):
    cross_tab = pd.crosstab(index=[categorical_values.iloc[:, i], categorical_values.iloc[:, i+1], categorical_values.iloc[:, i+2]], columns=churn2['Churn'])
    sns.set(style='whitegrid')
    cross_tab.plot(kind='bar', stacked=True, figsize=(10, 6))
    plt.title(f'Churn by {categorical_values.columns[i]}, {categorical_values.columns[i+1]}, and {categorical_values.columns[i+2]}')
    plt.xlabel(f'({categorical_values.columns[i]}, {categorical_values.columns[i+1]}, {categorical_values.columns[i+2]})')
    plt.ylabel('Count')
    plt.legend(title='Churn', loc='upper right', bbox_to_anchor=(1.15, 1))
    plt.show()

"""It can be seen that people who are are on the month-to-month contract,have no tech_support and pay with electronic checks churn a lot
while the customers who are on the two year contract, pay via credit cards and have no tech support churn the least

People who pay with electronic checks and have no tech support or online security churn a lot while customers have no internet service and pay with mailed checks churn the least

Customers with no tech support or oline security and have dsl churn the most while customers with no internet service, tech support or online security churn the least

Customers who use fibre optic are female and have no online backup churn the most while male customers with no internet service or online backup churn the least
"""

y

"""# Training the Keras model with cross validation and grid search"""

Xtrain,Xtest,Ytrain,Ytest=train_test_split(churn, y, test_size = 0.2, random_state=50)

input = Input(shape = (Xtrain.shape[1],))

Xtest.shape

Ytest.shape

"""Craeting a function that allows me to create different models"""

def create_model( optimizer='adam', hidden_units=32 ):
  hidden1 = Dense(hidden_units, activation='relu')(input)
  hidden2 = Dense(32, activation='relu')(hidden1)
  hidden3 = Dense(32, activation='relu')(hidden2)

  output = Dense(1, activation='sigmoid')(hidden3)
  model = Model(inputs = input, outputs = output)
  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

  return model

model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=1, hidden_units=32)

"""**Creating a dictionary that holds the relevant parameters and their keys**"""

param_grid = {
    'optimizer': ['adam', 'rmsprop'],
    'hidden_units': [32, 64, 128]
}

"""Using grid search to train the model"""

grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)
grid_result = grid.fit(Xtrain, Ytrain)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

"""*Getting the AUC and accuracy scores*"""

y_pred = grid_result.predict(Xtest)

auc_score = roc_auc_score(Ytest, y_pred)
print("AUC Score:", auc_score)

accuracy_scores = cross_val_score(model, Xtest, Ytest, cv=3)
print("Accuracy Scores:", accuracy_scores)

print(f"Mean Accuracy: {accuracy_scores.mean()}")
print(f"Standard Deviation: {accuracy_scores.std()}")

"""*Optimizing the model with new parameters*"""

model1 = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=1, hidden_units=32)

param_grid = {
    'optimizer': ['adam', 'rmsprop'],
    'hidden_units': [32, 64, 130]
}

grid = GridSearchCV(estimator=model1, param_grid=param_grid, cv=4)
grid_result1 = grid.fit(Xtrain, Ytrain)

print("Best: %f using %s" % (grid_result1.best_score_, grid_result1.best_params_))

y_pred = grid_result1.predict(Xtest)

auc_score = roc_auc_score(Ytest, y_pred)
print("AUC Score:", auc_score)

accuracy_scores = cross_val_score(model1, Xtest, Ytest, cv=3)
print("Accuracy Scores:", accuracy_scores)

print(f"Mean Accuracy: {accuracy_scores.mean()}")
print(f"Standard Deviation: {accuracy_scores.std()}")

model2 = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=1, hidden_units=32)

param_grid = {
    'optimizer': ['rmsprop', 'adadelta'],
    'hidden_units': [40, 80, 120]
}

grid = GridSearchCV(estimator=model2, param_grid=param_grid, cv=4)
grid_result2 = grid.fit(Xtrain, Ytrain)

print("Best: %f using %s" % (grid_result2.best_score_, grid_result2.best_params_))

y_pred = grid_result2.predict(Xtest)

auc_score = roc_auc_score(Ytest, y_pred)
print("AUC Score:", auc_score)

accuracy_scores = cross_val_score(model2, Xtest, Ytest, cv=3)
print("Accuracy Scores:", accuracy_scores)

print(f"Mean Accuracy: {accuracy_scores.mean()}")
print(f"Standard Deviation: {accuracy_scores.std()}")

"""**Saving the nodel with the highest accuracy**"""

model3 = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=1, hidden_units=32)
model = create_model('adadelta',160)
model.save('model.h5')

param_grid = {
    'optimizer': ['adam', 'adadelta'],
    'hidden_units': [64, 64, 160]
}

grid = GridSearchCV(estimator=model3, param_grid=param_grid, cv=4)
grid_result3 = grid.fit(Xtrain, Ytrain)

print("Best: %f using %s" % (grid_result3.best_score_, grid_result3.best_params_))

y_pred = grid_result3.predict(Xtest)

auc_score = roc_auc_score(Ytest, y_pred)
print("AUC Score:", auc_score)

accuracy_scores = cross_val_score(model3, Xtest, Ytest, cv=3)
print("Accuracy Scores:", accuracy_scores)

print(f"Mean Accuracy: {accuracy_scores.mean()}")
print(f"Standard Deviation: {accuracy_scores.std()}")

